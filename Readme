
 roboweld

 15 February 2021.

 I have started to separate my scanning function from the Keyence Driver Node. This will 
 leave the Driver untouched. If there is any change or update from ROS or Keyence it should
 not affect my scanning programs as long as they do not change the API's.

 I subscribe to the point cloud published by the Driver. Then I use that point cloud to do
 my own processing.

 5 February 2021.

 Added the .gitignore file to ignore both the build/ and devel/. Moved the Data/ folder to
 home directory instead of under roboweld/.

 Create a separate folder for each run for the profiles.

 4 February 2021.

 First, try to find the lines that best fit the side of the groove and the bottom of the 
 groove. The bottom of the groove is actually the top of the weldment of the first pass.
 Then, find the angle for the welding torch to bisect the angle between the found two lines.

 After that, it would be helpful to publish the axis of the points along the path for the 
 second pass. Next, change the motion node, that uses the URx, to drive the manipulator to
 do the welding.

 It is very important to note that I have changed the original Keyence Driver and now named
 it for two different purposes. 1. I called it concave_scanner and the other convex_scanner.
 The convex_scanner is for the back of the joint. There, the weldment comes up like a ridge.

 Now, I am going to change the concave_scanner agaain. I should make a copy of it first. 
 The new one will be called after_1st_scanner. This will give me the left edge in the groove.

 3 February 2021.

 It is necessary, if needed, to organise the files of Data from the program into directories.
 The organisation should be by date and time. There is a Directory - Data. Under that there
 are subdirectories for years and then for months.

 29 January 2021.

 The scanning of a Concave Groove is basically working well for me. The next thing is to scan
 the back of such a Welded Groove. This turns out to be a Convex Groove. So I must adapt the
 current keyence driver node into one that can do Convex scanning. Therefore, I want to change
 the naming of the current "keyence_driver_node" into "concave_scanner" and the new one as
 "convex_scanner". This means I need to cahnge the CMakeLists.txt, of the keyence_experimental
 package, to reflect the changes.

 18 January 2021.

 Over the last 10 days, work is being done on the overcoming problems of the Gradient and the
 Derivative of the Gradient. First found that the Gradient is not smooth and hence gives rise 
 to spikes in the Derivative of the Grandient. Hence the Second Derivative of Z will not be 
 accurate in finding the edges of the Groove. Then worked out averaging the Z, Derivative of Z,
 and Double Derivative of Z will give better result with less or smaller spikes.

 Then found that the average from 9 points to 15 points. A lot of time was spent on working out
 the algorithm in finding the Gradient, and the Derivative of the Gradient by just going through
 the data points of the profile Once. Making it correct must be very careful and time consuming
 in debugging it.

 8 January 2021.

 One of the biggeset problem now is the time taken to handle all the "cube" markers. It would be
 good if marker array can be used. Sample codes are needed to learn how to do it for marker arrays.

 Now the marker array seems to be working. However, the dot and double dot of z still seems to 
 behave in strange ways at some points.

 7 January 2021.

 Red colour markers are used to fill the groove.

 Be careful, the queue size of the marker should be big enough. The groove is about 30mm wide 
 and each point of the scanner is about 0.1 mm apart. Therefore, there will be about 300 points
 for each scan line. It is necessary to make sure both the publisher and the RViz setting to have
 about 350 to 400 queue size. Otherwise most of the markers will not appear.

 Now, some of the scan lines are not 30 mm wide. It is necessary to output a file with all the
 points and check how the dot (Derivative or the Gradient) and double dot (that is the Derivative
 of the Gradient) behave.

 It is found that some of the scan lines behave in a "strange" way in that the Maximum double dot
 of Z has a very Minimum double dot just before it. This near Minium double dot makes the min 
 found on the left side (before the Max) wrong. Now, I have made that to be about 10 points or 
 1 mm near it to be invalid (or discount it).

 31 December 2020.

 Now, the Keyence Laser Scanner can scan the workpiece and workout the cross section area and
 the volume of the groove from beginning to end.

 It would be better if the goove can be filled with a different colour marker to show the area
 and volume calculated.

 23 December 2020.

 Try to find out and display the height of the plane surface first.

 21 December 2020.

 I just aware that if the keyence driver node is not stopped by a controll C it will carry on
 building up the point cloud. That can become very large. 

 There should be a way to detect if the Laser scanner is switched on and off. On second thought
 this should be done by the program itself and do not need to find out from the scanner.

 Now I have the problem is because the robot and the scanner are not controlled by my program,
 roboweld, but by the Teach Pandent program. So, for the time being, leave it and just switch
 on and off the Keyence Driver Node by hand.

 One other observation, the profile given by the scanner will not be perfect if both the USB
 and the Ethernet are connected. The software in Windows will behave better when the TCP/IP 
 program is stopped. At the same time, if the the Driver Note is scanning, unplug the USB will
 give a better profile.

 Start to workout (1) the cross section area. That is the area given by the 1 line profile.
 (2) the cumulative volumn. That is the cross section area multiplied by the distance travelled.
 (3) Show both of them interactively in RViz.

 19 December 2020.

 Now, the profiles from the Keyence Laser Scanner are published in the world frame in one big
 point cloud.

 At the same time, because the Realsense D435i camera has already been installed and software
 is also working, just launch the driver will produce the point cloud:

   roslaunch realsense2_camera rs_camera.launch camera:=d435i enable_pointcloud:=true

 This will show the point cloud in RViz.

 17 December 2020.

 The Keyence Laser Scanner has been set to the ip address of 192.168.0.5 using the LJ Navigator
 in Windows. Also there the sampling rate was set to 20 Hz.

 This morning, I also connected the REMOTE of the scanner to the I/O controll relay from the
 UR5 controll box. This will only switch on the Laser under the control of the program.

 The next step is to put all the one line point clouds into a big point cloud. Each of the 
 one line point cloud has its reference frame as the optiical frame of the scanner. Before all
 these one line point clouds be concatinated into one big one, each of them must be transformed
 to the world coordinate to be consistant.

 Try to work out how this can be done.


 16 December 2020.

 It seems that I have already installed libsocket successfully for the Keyence Laser Scanner
 LJ7200. The next step will be use it to scan a groove and produce a profile in Point Cloud.

 1. Start the setupKeyence.launch - this will start the RViz and show the UR5 and let us to 
    Plan and Execute a pose.
 2. If the Kinect V2 can identify a groove then it can drive the torch or the Laser Scanner to 
    follow the groove
 3. Switch on the Laser as if switching on the Welding Torch.
 4. At the same time, switch on the RealSense camera to catch another Point Cloud of the same
    groove.
 5. Then we can compare the two, or even three Point Clouds captured by the three different
    sensors.

 Note: Do not worry about the Descartes for the time being and just use URx to drive the end
       effector.

 Create a new (ROS) node in roboweld_core and call it scan_node.

 Okay, I miss understood the whole thing! It is not necessary to write a separate node to get
 a PointCloud from the Keyence Scanner. According to the Readme file, just do a rosrun of the
 driver node with the _controller_ip will do. It will publish the PointCloud in the 'profiles'
 topic. Note that nothing will be published if nothing subscribes the topic.

 15 December 2020.

 Put the Keyence LJ7200 Laser Scanner on the Straight Fronius Torch holder together with
 the torch holder.

 Modified the roboweldKeyence.xacro file so that (1) when use the RViz and Planning and 
 Execution the Interactive Marker moves correctly, (2) the UR5 moves in front of the table
 instead of at the back of the table.

 28 November 2020.

 Cloned from Github, use VS Code at home and push back to Github.
 Okay, tested and it seems to be working.

 Needs to install freenect2 locally.

 27 November 2020.

 Changed from experiment back to roboweld.
 Start to use git and github in vs code.
 
 experiment

 28 October 2020.

 Copied the perception_node.cpp from 23 Oct 2019 / nrc-welding_ws.

 Before doing anything, to start the Kinect V2 first by

 $ roslaunch kinect2_bridge kinect2_bridge.launch

 Because the URx that I am going to use has the coordinate different from the one that I used
 therefore, as it is, when cropped some of the table is cropped.

 Not only this but because the X and Y axes exchanged, the algorithm to find the way points
 does not work. So it is necessary to change the X and Y in that algorithm as well!

 27 October 2020.

 It has been deceided to leave the Descartes to do trajectory planning for the time being.

 Instead URx will be used. This will incorporate the URx into this package.

 A new folder was placed under src/roboweld_core/ in parallel with src, script. urx is placed
 in that folder and a new file motion_URx.py is created.
 
 The idea is to go back to more than a year ago, use the Perception node to find the welding
 groove. Since it is going to use the URx for motion, it is not going to use Descartes anymore.

 12 October 2020.

 It would be better to plan to the path directly instead of referring to the center of the
 object.

 Using IK Solvers Other Than KDL With Calibration Data #226

 rosrun xacro xacro -o calibrated.urdf ur5_robot.urdf.xacro kinematics_config:=/<YOUR_PATH>/calibration.yaml

 5 October 2020.

 The end effector is not going to the center of the workpiece. It will start from the beginning
 of the trajectory.

 Now the default joint velocity was set to 0.03 radian per second.

 The EEF should find the path first, then move to the first point before starting the trajectory.

 9 September 2020.

 The moveit_setup_assistant was not working, did not display the robot after loading the model.
 Cloned the melodic-devel into the roboweld workspace and recompile with catkin_make, it is now
 working.

 It CAN drive the new UR5. Do not always do this. Test with the RViz simulation whenever
 possible. Change the ros_controllers.yaml file in the config folder under
 roboweld_moveit_config to use 
 action_ns: joint_trajectory_action
 for simulation.

 It has the RealSense D435i Camera sideway under the torch holder now. Take that away.
 Actually needs to rearrange according to the old one used in the lab.
 (1) Change the ur5.urdf.xaxro in the /fmauch_universal_robot/ur_description/urdf:
    (a) Comment out the wrist_3_passive_joint
    (b) Comment out the link tool0 at the end of the file
 (2) Change the roboweldfron1d435i.xacro in the /roboweld_support/urdf
    (a) 

 8 September 2020.

 This folder uses the bent torch and drives the real UR5.

 use the command:

 roslaunch roboweld_moveit_config roboweld_planning_execution sim:=false robot_ip:=192.168.0.103

 to drive the real UR5.

 To change it back to simulate in RViz, make sure the ros_controllers:yaml file in the 
 roboweld_moveit_config/config folder change the action_ns: to

 scaled_pos_traj_controller/follow_joint_trajectory


